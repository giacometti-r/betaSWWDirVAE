{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras as K\nfrom tensorflow.keras import Model, Sequential\nfrom tensorflow.keras.losses import Loss\nfrom tensorflow.keras.layers import Layer, Conv2D, Input, Conv2DTranspose, MaxPooling2D, Flatten, Dense\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-11-03T18:18:57.757694Z","iopub.execute_input":"2023-11-03T18:18:57.758437Z","iopub.status.idle":"2023-11-03T18:18:57.765453Z","shell.execute_reply.started":"2023-11-03T18:18:57.758402Z","shell.execute_reply":"2023-11-03T18:18:57.763928Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def getwhere(x):\n    ''' Calculate the 'where' mask that contains switches indicating which\n    index contained the max value when MaxPool2D was applied.  Using the\n    gradient of the sum is a nice trick to keep everything high level.'''\n    y_prepool, y_postpool = x\n    with tf.GradientTape() as tape:\n        y = tf.reduce_sum(y_postpool), y_prepool\n    return y","metadata":{"execution":{"iopub.status.busy":"2023-11-03T18:34:08.353620Z","iopub.execute_input":"2023-11-03T18:34:08.354002Z","iopub.status.idle":"2023-11-03T18:34:08.360199Z","shell.execute_reply.started":"2023-11-03T18:34:08.353969Z","shell.execute_reply":"2023-11-03T18:34:08.358821Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def convresblock(x, nfeats=8, ksize=3, deconv=False):\n    if not deconv:\n        y = Conv2DTranspose(nfeats, [ksize, ksize], padding='SAME', activation='elu')(x)               \n    else:\n        y = Conv2DTranspose(nfeats, [ksize, ksize], padding='SAME', activation='elu')(x)               \n    y = tf.nn.elu(y)\n    return y","metadata":{"execution":{"iopub.status.busy":"2023-11-03T18:34:12.186879Z","iopub.execute_input":"2023-11-03T18:34:12.187244Z","iopub.status.idle":"2023-11-03T18:34:12.194158Z","shell.execute_reply.started":"2023-11-03T18:34:12.187218Z","shell.execute_reply":"2023-11-03T18:34:12.192622Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n\nx_train = x_train.astype(\"float32\") / 255\ny_train = y_train.astype(\"float32\") / 255\nx_test = x_test.astype(\"float32\") / 255\ny_test = y_test.astype(\"float32\") / 255\n\n# The size of the kernel used for the MaxPooling2D\npool_size = 2\n# The total number of feature maps at each layer\nnfeats = [8, 16, 32, 64, 128]\n# The sizes of the pooling kernel at each layer\npool_sizes = np.array([1, 1, 1, 1, 1]) * pool_size\n# The convolution kernel size\nksize = 3\n# Number of epochs to train for\nepochs = 10\n# Batch size during training\nbatch_size = 128\n\nif pool_size == 2:\n    # if using a 5 layer net of pool_size = 2\n#     x_train = tf.pad(x_train, [[0, 0], [2, 2], [2, 2], [0, 0]],\n#                      mode='constant')\n#     x_test = tf.pad(x_test, [[0, 0], [2, 2], [2, 2], [0, 0]], mode='constant')\n    nlayers = 5\nelif pool_size == 3:\n    # if using a 3 layer net of pool_size = 3\n#     x_train = x_train[:, :, :-1, :-1]\n#     x_test = x_test[:, :, :-1, :-1]\n    nlayers = 3\nelse:\n    print('Script supports pool_size of 2 and 3.')","metadata":{"execution":{"iopub.status.busy":"2023-11-03T18:34:36.711124Z","iopub.execute_input":"2023-11-03T18:34:36.711492Z","iopub.status.idle":"2023-11-03T18:34:36.960134Z","shell.execute_reply.started":"2023-11-03T18:34:36.711462Z","shell.execute_reply":"2023-11-03T18:34:36.958222Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-11-03T18:18:58.304032Z","iopub.status.idle":"2023-11-03T18:18:58.304611Z","shell.execute_reply.started":"2023-11-03T18:18:58.304343Z","shell.execute_reply":"2023-11-03T18:18:58.304366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shape of input to train on (note that model is fully convolutional however)\ninput_shape = (None, x_train.shape[1], x_train.shape[2])\n# The final list of the size of axis=1 for all layers, including input\nnfeats_all = [input_shape[-1]] + nfeats\n\n# First build the encoder, all the while keeping track of the 'where' masks\n\n# We push the 'where' masks to the following list\nwheres = [None] * nlayers\npoolingOutputs = [None] * nlayers\ny = Input(shape=input_shape)\nfor i in range(nlayers):\n    y_prepool = convresblock(y, nfeats=nfeats_all[i + 1], ksize=ksize)\n    poolingOutputs[i] = MaxPooling2D([pool_sizes[i], pool_sizes[i]], [pool_sizes[i], pool_sizes[i]])(y_prepool)\n    wheres[i] = getwhere([y_prepool, poolingOutputs[i]])\n    y = poolingOutputs[i]","metadata":{"execution":{"iopub.status.busy":"2023-11-03T18:34:47.579697Z","iopub.execute_input":"2023-11-03T18:34:47.580069Z","iopub.status.idle":"2023-11-03T18:34:47.814352Z","shell.execute_reply.started":"2023-11-03T18:34:47.580040Z","shell.execute_reply":"2023-11-03T18:34:47.812557Z"},"trusted":true},"execution_count":20,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nlayers):\n\u001b[1;32m     13\u001b[0m     y_prepool \u001b[38;5;241m=\u001b[39m convresblock(y, nfeats\u001b[38;5;241m=\u001b[39mnfeats_all[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m], ksize\u001b[38;5;241m=\u001b[39mksize)\n\u001b[0;32m---> 14\u001b[0m     poolingOutputs[i] \u001b[38;5;241m=\u001b[39m \u001b[43mMaxPooling2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpool_sizes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool_sizes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mpool_sizes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool_sizes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_prepool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     wheres[i] \u001b[38;5;241m=\u001b[39m getwhere([y_prepool, poolingOutputs[i]])\n\u001b[1;32m     16\u001b[0m     y \u001b[38;5;241m=\u001b[39m poolingOutputs[i]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1973\u001b[0m, in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[1;32m   1970\u001b[0m   c_op \u001b[38;5;241m=\u001b[39m pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_FinishOperation(op_desc)\n\u001b[1;32m   1971\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1972\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m-> 1973\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e\u001b[38;5;241m.\u001b[39mmessage)\n\u001b[1;32m   1975\u001b[0m \u001b[38;5;66;03m# Record the current Python stack trace as the creating stacktrace of this\u001b[39;00m\n\u001b[1;32m   1976\u001b[0m \u001b[38;5;66;03m# TF_Operation.\u001b[39;00m\n\u001b[1;32m   1977\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extract_traceback:\n","\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"max_pooling2d_5\" (type MaxPooling2D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_5/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,?,1,128].\n\nCall arguments received by layer \"max_pooling2d_5\" (type MaxPooling2D):\n  â€¢ inputs=tf.Tensor(shape=(None, None, 1, 128), dtype=float32)"],"ename":"ValueError","evalue":"Exception encountered when calling layer \"max_pooling2d_5\" (type MaxPooling2D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_5/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,?,1,128].\n\nCall arguments received by layer \"max_pooling2d_5\" (type MaxPooling2D):\n  â€¢ inputs=tf.Tensor(shape=(None, None, 1, 128), dtype=float32)","output_type":"error"}]},{"cell_type":"code","source":"# Now build the decoder, and use the stored 'where' masks to place the features\nunpoolingOutputs = [None] * nlayers\nfor i in range(nlayers):\n    ind = nlayers - 1 - i    \n    in_shape = y.get_shape().as_list()\n    out_shape = [in_shape[1]*pool_sizes[ind], in_shape[2]*pool_sizes[ind]]\n    y = tf.image.resize(y, out_shape, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)   \n    y = tf.math.multiply(y, wheres[ind][0])\n    unpoolingOutputs[ind] = convresblock(y, nfeats=nfeats_all[ind], ksize=ksize, deconv=True)\n    y = unpoolingOutputs[ind]\noutputs=y","metadata":{"execution":{"iopub.status.busy":"2023-11-03T18:18:58.308671Z","iopub.status.idle":"2023-11-03T18:18:58.309065Z","shell.execute_reply.started":"2023-11-03T18:18:58.308882Z","shell.execute_reply":"2023-11-03T18:18:58.308900Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the model and it's mean square error loss, and compile it with Adam\ndef loss(img_input, y, poolingOutputs, unpoolingOutputs)\n    l2m0 = tf.nn.l2_loss(tf.keras.layers.Flatten(unpoolingOutputs[1]) - tf.keras.layers.Flatten(poolingOutputs[0]))\n    l2m1 = tf.nn.l2_loss(tf.keras.layers.Flatten(unpoolingOutputs[2]) - tf.keras.layers.Flatten(poolingOutputs[1]))\n    l2m2 = tf.nn.l2_loss(tf.keras.layers.Flatten(unpoolingOutputs[3]) - tf.keras.layers.Flatten(poolingOutputs[2]))\n    l2m3 = tf.nn.l2_loss(tf.keras.layers.Flatten(unpoolingOutputs[4]) - tf.keras.layers.Flatten(poolingOutputs[3]))\n    loss_l2 = tf.nn.l2_loss(tf.keras.layers.Flatten(img_input) -  tf.keras.layers.Flatten(y))\n    return loss_l2 + l2m0 + l2m1 + l2m2 + l2m3","metadata":{"execution":{"iopub.status.busy":"2023-11-03T18:18:58.310531Z","iopub.status.idle":"2023-11-03T18:18:58.310852Z","shell.execute_reply.started":"2023-11-03T18:18:58.310708Z","shell.execute_reply":"2023-11-03T18:18:58.310722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model(inputs=y, outputs=outputs)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T18:18:58.311812Z","iopub.status.idle":"2023-11-03T18:18:58.312118Z","shell.execute_reply.started":"2023-11-03T18:18:58.311973Z","shell.execute_reply":"2023-11-03T18:18:58.311997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}